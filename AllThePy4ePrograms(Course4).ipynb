{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "040fb8fc-b793-467d-9316-5263c5a951a9",
   "metadata": {},
   "source": [
    "# Fourth Course (Using Databases in Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf0cb5d-710d-40e9-b428-72f933c11f9f",
   "metadata": {},
   "source": [
    "## Module 2 (Assignment 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c21da-900b-4ea7-a8a1-948d238a4dee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Q:Counting Organizations\n",
    "This application will read the mailbox data (mbox.txt) and count the number of email messages per organization (i.e. domain name of the email address) using a database with the following schema to maintain the counts.\n",
    "\n",
    "CREATE TABLE Counts (org TEXT, count INTEGER)\n",
    "When you have run the program on mbox.txt upload the resulting database file above for grading.\n",
    "If you run the program multiple times in testing or with different files, make sure to empty out the data before each run.\n",
    "\n",
    "You can use this code as a starting point for your application: http://www.py4e.com/code3/emaildb.py.\n",
    "\n",
    "The data file for this application is the same as in previous assignments: http://www.py4e.com/code3/mbox.txt.\n",
    "\n",
    "Because the sample code is using an UPDATE statement and committing the results to the database as each record is read in the loop, it might take as long as a few minutes to process all the data. The commit insists on completely writing all the data to disk every time it is called.\n",
    "\n",
    "The program can be speeded up greatly by moving the commit operation outside of the loop. In any database program, there is a balance between the number of operations you execute between commits and the importance of not losing the results of operations that have not yet been committed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948216e2-72bd-488e-bd6a-6ad24d6526c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter file name:  mbox.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iupui.edu 536\n",
      "umich.edu 491\n",
      "indiana.edu 178\n",
      "caret.cam.ac.uk 157\n",
      "vt.edu 110\n",
      "uct.ac.za 96\n",
      "media.berkeley.edu 56\n",
      "ufp.pt 28\n",
      "gmail.com 25\n",
      "et.gatech.edu 17\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('emaildb.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS Counts')\n",
    "cur.execute('CREATE TABLE Counts (org TEXT, count INTEGER)')\n",
    "\n",
    "fname = input('Enter file name: ')\n",
    "if len(fname) < 1:\n",
    "    fname = 'mbox-short.txt'\n",
    "\n",
    "fh = open(fname)\n",
    "for line in fh:\n",
    "    if not line.startswith('From: '): continue\n",
    "    pieces = line.split()\n",
    "    email = pieces[1]\n",
    "    org = email.split('@')[1]  \n",
    "    cur.execute('SELECT count FROM Counts WHERE org = ?', (org,))\n",
    "    row = cur.fetchone()\n",
    "    if row is None:\n",
    "        cur.execute('INSERT INTO Counts (org, count) VALUES (?, 1)', (org,))\n",
    "    else:\n",
    "        cur.execute('UPDATE Counts SET count = count + 1 WHERE org = ?', (org,))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "sqlstr = 'SELECT org, count FROM Counts ORDER BY count DESC LIMIT 10'\n",
    "for row in cur.execute(sqlstr):\n",
    "    print(str(row[0]), row[1])\n",
    "\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2299a1-83b1-47ec-89f3-6c106782f60f",
   "metadata": {},
   "source": [
    "## Module 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ff4a4-fb2e-4b04-855e-3fbeb62ac28e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Q:Musical Track Database\n",
    "This application will read an iTunes export file in CSV format and produce a properly normalized database with this structure:\n",
    "\n",
    "CREATE TABLE Artist (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    name    TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Genre (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    name    TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Album (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    artist_id  INTEGER,\n",
    "    title   TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Track (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY \n",
    "        AUTOINCREMENT UNIQUE,\n",
    "    title TEXT  UNIQUE,\n",
    "    album_id  INTEGER,\n",
    "    genre_id  INTEGER,\n",
    "    len INTEGER, rating INTEGER, count INTEGER\n",
    ");\n",
    "If you run the program multiple times in testing or with different files, make sure to empty out the data before each run.\n",
    "\n",
    "You can use this code as a starting point for your application: http://www.py4e.com/code3/tracks.zip. The ZIP file contains the tracks.csv file to be used for this assignment. You can export your own tracks from iTunes and create a database, but for the database that you turn in for this assignment, only use the tracks.csv data that is provided. You can adapt the tracks_csv.py application in the zip file to complete the assignment.\n",
    "\n",
    "To grade this assignment, the program will run a query like this on your uploaded database and look for the data it expects to see:\n",
    "\n",
    "SELECT Track.title, Artist.name, Album.title, Genre.name \n",
    "    FROM Track JOIN Genre JOIN Album JOIN Artist \n",
    "    ON Track.genre_id = Genre.ID and Track.album_id = Album.id \n",
    "        AND Album.artist_id = Artist.id\n",
    "    ORDER BY Artist.name LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ea3793-4f4f-48d3-b871-c31715721141",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('trackdb.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.executescript('''\n",
    "DROP TABLE IF EXISTS Artist;\n",
    "DROP TABLE IF EXISTS Genre;\n",
    "DROP TABLE IF EXISTS Album;\n",
    "DROP TABLE IF EXISTS Track;\n",
    "\n",
    "CREATE TABLE Artist (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    name    TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Genre (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    name    TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Album (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,\n",
    "    artist_id  INTEGER,\n",
    "    title   TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Track (\n",
    "    id  INTEGER NOT NULL PRIMARY KEY \n",
    "        AUTOINCREMENT UNIQUE,\n",
    "    title TEXT  UNIQUE,\n",
    "    album_id  INTEGER,\n",
    "    genre_id  INTEGER,\n",
    "    len INTEGER, rating INTEGER, count INTEGER\n",
    ");\n",
    "''')\n",
    "\n",
    "handle = open('tracks.csv')\n",
    "\n",
    "\n",
    "for line in handle:\n",
    "    line = line.strip();\n",
    "    pieces = line.split(',')\n",
    "    if len(pieces) < 7 : continue\n",
    "\n",
    "    name = pieces[0]\n",
    "    artist = pieces[1]\n",
    "    album = pieces[2]\n",
    "    count = pieces[3]\n",
    "    rating = pieces[4]\n",
    "    length = pieces[5]\n",
    "    genre = pieces[6]\n",
    "\n",
    "\n",
    "    cur.execute('''INSERT OR IGNORE INTO Artist (name) \n",
    "        VALUES ( ? )''', ( artist, ) )\n",
    "    cur.execute('SELECT id FROM Artist WHERE name = ? ', (artist, ))\n",
    "    artist_id = cur.fetchone()[0]\n",
    "\n",
    "    cur.execute('''INSERT OR IGNORE INTO Album (title, artist_id) \n",
    "        VALUES ( ?, ? )''', ( album, artist_id ) )\n",
    "    cur.execute('SELECT id FROM Album WHERE title = ? ', (album, ))\n",
    "    album_id = cur.fetchone()[0]\n",
    "\n",
    "    cur.execute('''INSERT OR IGNORE INTO Genre (name) \n",
    "        VALUES ( ? )''', (genre, ) )\n",
    "    cur.execute('SELECT id FROM Genre WHERE name = ? ', (genre, ))\n",
    "    genre_id = cur.fetchone()[0]\n",
    "\n",
    "    cur.execute('''INSERT OR REPLACE INTO Track\n",
    "        (title, album_id, len, rating, count, genre_id) \n",
    "        VALUES ( ?, ?, ?, ?, ?, ? )''', \n",
    "        ( name, album_id, length, rating, count, genre_id) )\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6907450a-0b4b-49d9-b056-ac296432c5aa",
   "metadata": {},
   "source": [
    "## Module 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73584b62-4b48-488e-8ed7-0d0090ec7eb7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Q:Instructions\n",
    "This application will read roster data in JSON format, parse the file, and then produce an SQLite database that contains a User, Course, and Member table and populate the tables from the data file.\n",
    "\n",
    "You can base your solution on this code: http://www.py4e.com/code3/roster/roster.py - this code is incomplete as you need to modify the program to store the role column in the Member table to complete the assignment.\n",
    "\n",
    "Each student gets their own file for the assignment. Download this file:\n",
    "\n",
    "\n",
    "Dowload your roster.json data\n",
    "And save it as roster_data.json. Move the downloaded file into the same folder as your roster.py program.\n",
    "Once you have made the necessary changes to the program and it has been run successfully reading the above JSON data, run the following SQL command:\n",
    "\n",
    "SELECT User.name,Course.title, Member.role FROM \n",
    "    User JOIN Member JOIN Course \n",
    "    ON User.id = Member.user_id AND Member.course_id = Course.id\n",
    "    ORDER BY User.name DESC, Course.title DESC, Member.role DESC LIMIT 2;\n",
    "The output should look as follows:\n",
    "Zuzanna|si110|0\n",
    "Zuriel|si106|0\n",
    "Once that query gives the correct data, run this query:\n",
    "SELECT 'XYZZY' || hex(User.name || Course.title || Member.role ) AS X FROM \n",
    "    User JOIN Member JOIN Course \n",
    "    ON User.id = Member.user_id AND Member.course_id = Course.id\n",
    "    ORDER BY X LIMIT 1;\n",
    "You should get one row with a string that looks like XYZZY53656C696E613333."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51cf577-3486-4b6d-84e9-325a17d2c6a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter file name:  roster_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('rosterdb.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Do some setup\n",
    "cur.executescript('''\n",
    "DROP TABLE IF EXISTS User;\n",
    "DROP TABLE IF EXISTS Member;\n",
    "DROP TABLE IF EXISTS Course;\n",
    "\n",
    "CREATE TABLE User (\n",
    "    id     INTEGER PRIMARY KEY,\n",
    "    name   TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Course (\n",
    "    id     INTEGER PRIMARY KEY,\n",
    "    title  TEXT UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE Member (\n",
    "    user_id     INTEGER,\n",
    "    course_id   INTEGER,\n",
    "    role        INTEGER,\n",
    "    PRIMARY KEY (user_id, course_id)\n",
    ")\n",
    "''')\n",
    "\n",
    "fname = input('Enter file name: ')\n",
    "if len(fname) < 1:\n",
    "    fname = 'roster_data_sample.json'\n",
    "\n",
    "#   [ \"Charley\", \"si110\", 1 ],\n",
    "#   [ \"Mea\", \"si110\", 0 ],\n",
    "\n",
    "str_data = open(fname).read()\n",
    "json_data = json.loads(str_data)\n",
    "\n",
    "for entry in json_data:\n",
    "\n",
    "    name = entry[0]\n",
    "    title = entry[1]\n",
    "    role = entry[2]\n",
    "\n",
    "    cur.execute('''INSERT OR IGNORE INTO User (name)\n",
    "        VALUES ( ? )''', ( name, ) )\n",
    "    cur.execute('SELECT id FROM User WHERE name = ? ', (name, ))\n",
    "    user_id = cur.fetchone()[0]\n",
    "\n",
    "    cur.execute('''INSERT OR IGNORE INTO Course (title)\n",
    "        VALUES ( ? )''', ( title, ) )\n",
    "    cur.execute('SELECT id FROM Course WHERE title = ? ', (title, ))\n",
    "    course_id = cur.fetchone()[0]\n",
    "\n",
    "    cur.execute('''INSERT OR REPLACE INTO Member\n",
    "        (user_id, course_id, role) VALUES ( ?, ?, ?)''',\n",
    "        ( user_id, course_id, role ) )\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501fbc3-cd4b-4146-b4ec-9e7d1e3bf7f6",
   "metadata": {},
   "source": [
    "## Module 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6a17b-00ee-4c70-9c32-73747b10dfba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Q:Retrieving GEOData\n",
    "Download the code from www.py4e.com/code3/opengeo.zip - then unzip the file and edit where.data to add an address nearby where you live - don't reveal where you live. Then run the geoload.py to lookup all of the entries in where.data (including the new one) and produce the geodata.sqlite. Then run geodump.py to read the database and produce where.js. You can run the programs and then scroll back to take your screen shots when the program finishes. Then open where.html to visualize the map. Take screen shots as described below. Make sure that your added location shows in all three of your screen shots.\n",
    "\n",
    "\n",
    "This is a relatively simple assignment. Don't take off points for little mistakes. If they seem to have done the assignment give them full credit. Feel free to make suggestions if there are small mistakes. Please keep your comments positive and useful. If you do not take grading seriously, the instructors may delete your response and you will lose points.\n",
    "Assignment specification:\n",
    "\n",
    "Please Upload Your Submission:\n",
    "\n",
    "Screen shot (JPG or PNG - Maximum 1MB) of the geoload.py program output in the command line including your highlighted added location.No file chosen\n",
    "(Please use PNG or JPG files 1024KB max)\n",
    "\n",
    "Screen shot (JPG or PNG - Maximum 1MB) of the geodump.py program output in the command line including your highlighted added location.No file chosen\n",
    "(Please use PNG or JPG files 1024KB max)\n",
    "\n",
    "Screen shot (JPG or PNG - Maximum 1MB) of the map zoomed into the location that you added after you open where.html in a browserNo file chosen\n",
    "(Please use PNG or JPG files 1024KB max)\n",
    "\n",
    "Enter optional comments below\n",
    "\n",
    "\n",
    "Make sure each uploaded image file is smaller than 1M. Total upload size limited to 2M\n",
    "\n",
    "The total number of points for this assignment is 10. You will get up to 3 points from your instructor. Your peers will give you a grade from 0 - 4. You will get 1 for each peer assignment you assess. You need to grade a minimum of 3 peer assignments. You can grade up to 5 peer assignments if you like but grading extra assignment will not increase your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272aef4-9d0c-435d-bf17-73263f9a64c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# geoload.py\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import http\n",
    "import sqlite3\n",
    "import json\n",
    "import time\n",
    "import ssl\n",
    "import sys\n",
    "\n",
    "# https://py4e-data.dr-chuck.net/opengeo?q=Ann+Arbor%2C+MI\n",
    "serviceurl = 'https://py4e-data.dr-chuck.net/opengeo?'\n",
    "\n",
    "# Additional detail for urllib\n",
    "# http.client.HTTPConnection.debuglevel = 1\n",
    "\n",
    "conn = sqlite3.connect('opengeo.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Locations (address TEXT, geodata TEXT)''')\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "fh = open(\"where.data\")\n",
    "count = 0\n",
    "nofound = 0\n",
    "for line in fh:\n",
    "    if count > 100 :\n",
    "        print('Retrieved 100 locations, restart to retrieve more')\n",
    "        break\n",
    "\n",
    "    address = line.strip()\n",
    "    print('')\n",
    "    cur.execute(\"SELECT geodata FROM Locations WHERE address= ?\",\n",
    "        (memoryview(address.encode()), ))\n",
    "\n",
    "    try:\n",
    "        data = cur.fetchone()[0]\n",
    "        print(\"Found in database\", address)\n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    parms = dict()\n",
    "    parms['q'] = address\n",
    "\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "    data = uh.read().decode()\n",
    "    print('Retrieved', len(data), 'characters', data[:20].replace('\\n', ' '))\n",
    "    count = count + 1\n",
    "\n",
    "    try:\n",
    "        js = json.loads(data)\n",
    "    except:\n",
    "        print(data)  # We print in case unicode causes an error\n",
    "        continue\n",
    "\n",
    "    if not js or 'features' not in js:\n",
    "        print('==== Download error ===')\n",
    "        print(data)\n",
    "        break\n",
    "\n",
    "    if len(js['features']) == 0:\n",
    "        print('==== Object not found ====')\n",
    "        nofound = nofound + 1\n",
    "\n",
    "    cur.execute('''INSERT INTO Locations (address, geodata)\n",
    "        VALUES ( ?, ? )''',\n",
    "        (memoryview(address.encode()), memoryview(data.encode()) ) )\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    if count % 10 == 0 :\n",
    "        print('Pausing for a bit...')\n",
    "        #time.sleep(5)\n",
    "\n",
    "if nofound > 0:\n",
    "    print('Number of features for which the location could not be found:', nofound)\n",
    "\n",
    "print(\"Run geodump.py to read the data from the database so you can vizualize it on a map.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3579b8-91d7-44c3-853e-0e8ee16d1fb4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# geodump.py\n",
    "import sqlite3\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "conn = sqlite3.connect('opengeo.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('SELECT * FROM Locations')\n",
    "fhand = codecs.open('where.js', 'w', \"utf-8\")\n",
    "fhand.write(\"myData = [\\n\")\n",
    "count = 0\n",
    "for row in cur :\n",
    "    data = str(row[1].decode())\n",
    "    try: js = json.loads(str(data))\n",
    "    except: continue\n",
    "\n",
    "    if len(js['features']) == 0: continue\n",
    "\n",
    "    try:\n",
    "        lat = js['features'][0]['geometry']['coordinates'][1]\n",
    "        lng = js['features'][0]['geometry']['coordinates'][0]\n",
    "        where = js['features'][0]['properties']['display_name']\n",
    "        where = where.replace(\"'\", \"\")\n",
    "    except:\n",
    "        print('Unexpected format')\n",
    "        print(js)\n",
    "\n",
    "    try :\n",
    "        print(where, lat, lng)\n",
    "\n",
    "        count = count + 1\n",
    "        if count > 1 : fhand.write(\",\\n\")\n",
    "        output = \"[\"+str(lat)+\",\"+str(lng)+\", '\"+where+\"']\"\n",
    "        fhand.write(output)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "fhand.write(\"\\n];\\n\")\n",
    "cur.close()\n",
    "fhand.close()\n",
    "print(count, \"records written to where.js\")\n",
    "print(\"Open where.html to view the data in a browser\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
